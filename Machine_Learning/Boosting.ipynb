{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# **_Boosting Algorithm ([AdaBoost](https://www.youtube.com/watch?v=LsK-xG1cLYA))_**\n",
    "### __*Learning a set of methods on weighted examples*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### __*Import Libraries*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### __*Decision Stump*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "class DecisionStump:\n",
    "    def __init__(self):\n",
    "        self.polarity = 1           # It is a positive or negative sample\n",
    "        self.feature_idx = None     # Which Feature will this Decision Stump use\n",
    "        self.threshold = None       # The amount by which we choose\n",
    "        self.alpha = None           # How important this Decision Stump is final prediction\n",
    "\n",
    "    def predict(self, X):\n",
    "        n_samples = X.shape[0]\n",
    "        X_column = X[:, self.feature_idx]\n",
    "        predictions = np.ones(n_samples)\n",
    "        if self.polarity == 1:\n",
    "            predictions[X_column < self.threshold] = -1\n",
    "        else:\n",
    "            predictions[X_column > self.threshold] = -1\n",
    "\n",
    "        return predictions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### __*AdaBoost Model*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "class AdaBoost:\n",
    "    def __init__(self, n_clf=5):\n",
    "        self.n_clf = n_clf\n",
    "        self.clfs = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\" Train the AdaBoost Model \"\"\"\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Initialize weights to 1/N\n",
    "        w = np.full(n_samples, (1 / n_samples))\n",
    "\n",
    "        # Iterate through classifiers\n",
    "        for _ in range(self.n_clf):\n",
    "            clf = DecisionStump()\n",
    "            min_error = float(\"inf\")\n",
    "\n",
    "            # Greedy search to find the best threshold and feature\n",
    "            for feature_i in range(n_features):\n",
    "                X_column = X[:, feature_i]\n",
    "                thresholds = np.unique(X_column)\n",
    "\n",
    "                for idx in range(len(thresholds) - 1):\n",
    "                    # Calculate the threshold\n",
    "                    threshold = (thresholds[idx] + thresholds[idx + 1]) / 2\n",
    "\n",
    "                    # Predict with polarity 1\n",
    "                    p = 1\n",
    "                    predictions = np.ones(n_samples)\n",
    "                    predictions[X_column < threshold] = -1\n",
    "\n",
    "                    # Error = sum of misclassified samples weight\n",
    "                    error = sum(w[y != predictions])\n",
    "\n",
    "                    # Swap polarity & fix error\n",
    "                    if error > 0.5:\n",
    "                        error = 1 - error\n",
    "                        p = -1\n",
    "\n",
    "                    # Save the best configuration\n",
    "                    if error < min_error:\n",
    "                        clf.polarity = p\n",
    "                        clf.threshold = threshold\n",
    "                        clf.feature_idx = feature_i\n",
    "                        min_error = error\n",
    "\n",
    "            # Calculate alpha (How much impact this rule has on final output)\n",
    "            EPS = 1e-10  # Make sure we never divide by 0\n",
    "            clf.alpha = 0.5 * np.log((1.0 - min_error + EPS) / (min_error + EPS))\n",
    "\n",
    "            # Calculate predictions\n",
    "            predictions = clf.predict(X)\n",
    "\n",
    "            # Update weights & normalization to one\n",
    "            w *= np.exp(-clf.alpha * y * predictions)\n",
    "            w /= np.sum(w)\n",
    "\n",
    "            # Save classifier\n",
    "            self.clfs.append(clf)\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"Create List of predictions for every classifier, sum them & normalize\"\"\"\n",
    "        clf_preds = [clf.alpha * clf.predict(X) for clf in self.clfs]\n",
    "        y_prediction = np.sum(clf_preds, axis=0)\n",
    "        y_prediction = np.sign(y_prediction)\n",
    "\n",
    "        return y_prediction\n",
    "\n",
    "    def show_classification(self, Table, Translate):\n",
    "        Index = 0\n",
    "        for clf in self.clfs:\n",
    "            Index += 1\n",
    "            if Index < 10:\n",
    "                print(f'0{Index}. Decision: {Table.columns[clf.feature_idx]} | '\n",
    "                      f'Threshold: {\"Less Than\" if clf.polarity == -1 else \"Greater Than\"} '\n",
    "                      f'{round(clf.threshold, 3)} is {Translate[1]} | Power of Rule: {round(clf.alpha, 3)}')\n",
    "            else:\n",
    "                print(f'{Index}. Decision: {Table.columns[clf.feature_idx]} | '\n",
    "                      f'Threshold: {\"Less Than\" if clf.polarity == -1 else \"Greater Than\"} '\n",
    "                      f'{round(clf.threshold, 3)} is {Translate[1]} | Power of Rule: {round(clf.alpha, 3)}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### __*Final Tests*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "class ModelTesting:\n",
    "    def __init__(self, X_Train, y_Train, X_Test, y_Test, Model=None, y_Prediction=None):\n",
    "        self.X_Train = X_Train\n",
    "        self.y_Train = y_Train\n",
    "        self.X_Test = X_Test\n",
    "        self.y_Test = y_Test\n",
    "        self.Model = Model\n",
    "        self.y_Prediction = y_Prediction\n",
    "\n",
    "    def optim(self, Max_Cls=100, Stop=False, Gap=1):\n",
    "        \"\"\"\n",
    "        Find optimal number of classifiers\n",
    "        :return: Best Number of Classifiers\n",
    "        \"\"\"\n",
    "        Max_Classifier = Max_Cls\n",
    "        Last_Test = 0\n",
    "        Last_Number = 0\n",
    "        Drop = 0\n",
    "\n",
    "        for num in range(1, Max_Classifier):\n",
    "            Model = AdaBoost(n_clf=num)\n",
    "            Model.fit(self.X_Train, self.y_Train)\n",
    "            y_Prediction = Model.predict(self.X_Test)\n",
    "            Test = self.accuracy(y_Prediction) + self.precision(y_Prediction)\\\n",
    "                   + self.recall(y_Prediction) + self.f1score(y_Prediction)\n",
    "\n",
    "            if Stop and Test < Last_Test:\n",
    "                Drop += 1\n",
    "                if Drop > Gap:\n",
    "                    return Last_Number\n",
    "            elif Test > Last_Test:\n",
    "                self.Model = Model\n",
    "                self.y_Prediction = y_Prediction\n",
    "                Last_Test, Last_Number = Test, num\n",
    "            else:\n",
    "                Drop = 0\n",
    "\n",
    "        return Last_Number\n",
    "\n",
    "    def accuracy(self, y_Prediction=None):\n",
    "        \"\"\" Test the accuracy of model \"\"\"\n",
    "        y_Prediction = self.y_Prediction if y_Prediction is None else y_Prediction\n",
    "        return np.sum(self.y_Test == y_Prediction) / len(self.y_Test)\n",
    "\n",
    "    def precision(self, y_Prediction=None):\n",
    "        \"\"\" Test the precision of model \"\"\"\n",
    "        y_Prediction = self.y_Prediction if y_Prediction is None else y_Prediction\n",
    "        TP = np.sum(self.y_Test[self.y_Test == y_Prediction] == 1)\n",
    "        # print(f'{y_Prediction}\\n{self.y_Test}\\nTP:{TP} P:{len(self.y_Test[self.y_Test == 1])}')\n",
    "        return TP / len(self.y_Test[self.y_Test == 1])\n",
    "\n",
    "    def recall(self, y_Prediction=None):\n",
    "        \"\"\" Test the recall of model \"\"\"\n",
    "        y_Prediction = self.y_Prediction if y_Prediction is None else y_Prediction\n",
    "        TP = np.sum(self.y_Test[self.y_Test == y_Prediction] == 1)\n",
    "        FN = np.sum(self.y_Test[self.y_Test != y_Prediction] == -1)\n",
    "        # print(f'{y_Prediction}\\n{self.y_Test}\\nTP:{TP} FN:{FN} TP + FN:{TP + FN}')\n",
    "        return TP / (TP + FN)\n",
    "\n",
    "    def f1score(self, y_Prediction=None):\n",
    "        \"\"\" Test the f1 score of model \"\"\"\n",
    "        y_Prediction = self.y_Prediction if y_Prediction is None else y_Prediction\n",
    "        Precision = self.precision(y_Prediction)\n",
    "        Recall = self.recall(y_Prediction)\n",
    "        return 2*((Precision * Recall) / (Precision + Recall))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### __*[Heart Attack Dataset](https://www.kaggle.com/datasets/rashikrahmanpritom/heart-attack-analysis-prediction-dataset)*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n0   63    1   3     145   233    1        0       150     0      2.3    0   \n1   37    1   2     130   250    0        1       187     0      3.5    0   \n2   41    0   1     130   204    0        0       172     0      1.4    2   \n3   56    1   1     120   236    0        1       178     0      0.8    2   \n4   57    0   0     120   354    0        1       163     1      0.6    2   \n\n   caa  thall  output  \n0    0      1       1  \n1    0      2       1  \n2    0      2       1  \n3    0      2       1  \n4    0      2       1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>sex</th>\n      <th>cp</th>\n      <th>trtbps</th>\n      <th>chol</th>\n      <th>fbs</th>\n      <th>restecg</th>\n      <th>thalachh</th>\n      <th>exng</th>\n      <th>oldpeak</th>\n      <th>slp</th>\n      <th>caa</th>\n      <th>thall</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>63</td>\n      <td>1</td>\n      <td>3</td>\n      <td>145</td>\n      <td>233</td>\n      <td>1</td>\n      <td>0</td>\n      <td>150</td>\n      <td>0</td>\n      <td>2.3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>37</td>\n      <td>1</td>\n      <td>2</td>\n      <td>130</td>\n      <td>250</td>\n      <td>0</td>\n      <td>1</td>\n      <td>187</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>41</td>\n      <td>0</td>\n      <td>1</td>\n      <td>130</td>\n      <td>204</td>\n      <td>0</td>\n      <td>0</td>\n      <td>172</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>56</td>\n      <td>1</td>\n      <td>1</td>\n      <td>120</td>\n      <td>236</td>\n      <td>0</td>\n      <td>1</td>\n      <td>178</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>57</td>\n      <td>0</td>\n      <td>0</td>\n      <td>120</td>\n      <td>354</td>\n      <td>0</td>\n      <td>1</td>\n      <td>163</td>\n      <td>1</td>\n      <td>0.6</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show structure of dataset\n",
    "heart_raw = pd.read_csv('data/heart.csv')\n",
    "heart_raw.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63.0, 1.0, 3.0, 145.0, 233.0, 1.0, 0.0, 150.0, 0.0, 2.3, 0.0, 0.0, 1.0, 1]\n",
      "[47.0, 1.0, 0.0, 110.0, 275.0, 0.0, 0.0, 118.0, 1.0, 1.0, 1.0, 1.0, 2.0, -1]\n",
      "Translation: {1: 'Positive', -1: 'Negative'}\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset\n",
    "dataset = DataLoader.load_dataset('data/heart.csv')\n",
    "train_data, test_data, translate = DataLoader.tt_split_dataset(dataset, train=0.8, shuffle=False, data='heart')\n",
    "X_train, y_train = DataLoader.xy_split_dataset(train_data)\n",
    "X_test, y_test = DataLoader.xy_split_dataset(test_data)\n",
    "\n",
    "# Show structure of new dataset\n",
    "print(f'{train_data[0]}\\n{train_data[-1]}\\nTranslation: {translate}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuber of classifiers: 5\n",
      "Accuracy: 81.97% | Precision: 84.85% | Recall: 82.35% | F1 Score: 83.58%\n"
     ]
    }
   ],
   "source": [
    "# Test the AdaBoost Model\n",
    "model = ModelTesting(X_train, y_train, X_test, y_test)\n",
    "n_cls = model.optim(Max_Cls=20, Stop=False, Gap=5)\n",
    "acc = model.accuracy()\n",
    "pre = model.precision()\n",
    "rec = model.recall()\n",
    "f1s = model.f1score()\n",
    "\n",
    "# Print the Results\n",
    "print(f'Nuber of classifiers: {n_cls}\\n'\n",
    "      f'Accuracy: {round(acc*100, 2)}% | Precision: {round(pre*100, 2)}% | '\n",
    "      f'Recall: {round(rec*100, 2)}% | F1 Score: {round(f1s*100, 2)}%')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01. Decision: cp | Threshold: Greater Than 0.5 is Positive | Power of Rule: 0.589\n",
      "02. Decision: caa | Threshold: Less Than 0.5 is Positive | Power of Rule: 0.528\n",
      "03. Decision: slp | Threshold: Greater Than 1.5 is Positive | Power of Rule: 0.487\n",
      "04. Decision: sex | Threshold: Less Than 0.5 is Positive | Power of Rule: 0.408\n",
      "05. Decision: thall | Threshold: Less Than 2.5 is Positive | Power of Rule: 0.37\n"
     ]
    }
   ],
   "source": [
    "# Show the decision-making process\n",
    "model.Model.show_classification(heart_raw, translate)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "\n",
    "### __*[Cancer Dataset](https://www.kaggle.com/datasets/erdemtaha/cancer-data)*__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n0    842302         M        17.99         10.38          122.80     1001.0   \n1    842517         M        20.57         17.77          132.90     1326.0   \n2  84300903         M        19.69         21.25          130.00     1203.0   \n3  84348301         M        11.42         20.38           77.58      386.1   \n4  84358402         M        20.29         14.34          135.10     1297.0   \n\n   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n0          0.11840           0.27760          0.3001              0.14710   \n1          0.08474           0.07864          0.0869              0.07017   \n2          0.10960           0.15990          0.1974              0.12790   \n3          0.14250           0.28390          0.2414              0.10520   \n4          0.10030           0.13280          0.1980              0.10430   \n\n   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n0  ...         25.38          17.33           184.60      2019.0   \n1  ...         24.99          23.41           158.80      1956.0   \n2  ...         23.57          25.53           152.50      1709.0   \n3  ...         14.91          26.50            98.87       567.7   \n4  ...         22.54          16.67           152.20      1575.0   \n\n   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n0            0.1622             0.6656           0.7119                0.2654   \n1            0.1238             0.1866           0.2416                0.1860   \n2            0.1444             0.4245           0.4504                0.2430   \n3            0.2098             0.8663           0.6869                0.2575   \n4            0.1374             0.2050           0.4000                0.1625   \n\n   symmetry_worst  fractal_dimension_worst  \n0          0.4601                  0.11890  \n1          0.2750                  0.08902  \n2          0.3613                  0.08758  \n3          0.6638                  0.17300  \n4          0.2364                  0.07678  \n\n[5 rows x 32 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>diagnosis</th>\n      <th>radius_mean</th>\n      <th>texture_mean</th>\n      <th>perimeter_mean</th>\n      <th>area_mean</th>\n      <th>smoothness_mean</th>\n      <th>compactness_mean</th>\n      <th>concavity_mean</th>\n      <th>concave points_mean</th>\n      <th>...</th>\n      <th>radius_worst</th>\n      <th>texture_worst</th>\n      <th>perimeter_worst</th>\n      <th>area_worst</th>\n      <th>smoothness_worst</th>\n      <th>compactness_worst</th>\n      <th>concavity_worst</th>\n      <th>concave points_worst</th>\n      <th>symmetry_worst</th>\n      <th>fractal_dimension_worst</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>842302</td>\n      <td>M</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>842517</td>\n      <td>M</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>84300903</td>\n      <td>M</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>84348301</td>\n      <td>M</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>84358402</td>\n      <td>M</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 32 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show structure of dataset\n",
    "cancer_raw = pd.read_csv('data/cancer.csv')\n",
    "cancer_raw.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.99, 10.38, 122.8, 1001.0, 0.1184, 0.2776, 0.3001, 0.1471, 0.2419, 0.07871, 1.095, 0.9053, 8.589, 153.4, 0.006399, 0.04904, 0.05373, 0.01587, 0.03003, 0.006193, 25.38, 17.33, 184.6, 2019.0, 0.1622, 0.6656, 0.7119, 0.2654, 0.4601, 0.1189, 1]\n",
      "[12.27, 29.97, 77.42, 465.4, 0.07699, 0.03398, 0.0, 0.0, 0.1701, 0.0596, 0.4455, 3.647, 2.884, 35.13, 0.007339, 0.008243, 0.0, 0.0, 0.03141, 0.003136, 13.45, 38.05, 85.08, 558.9, 0.09422, 0.05213, 0.0, 0.0, 0.2409, 0.06743, -1]\n",
      "Translation: {1: 'M (Positive)', -1: 'B (Negative)'}\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset\n",
    "dataset = DataLoader.load_dataset('data/cancer.csv')\n",
    "train_data, test_data, translate = DataLoader.tt_split_dataset(dataset, train=0.8, shuffle=False, data='cancer')\n",
    "X_train, y_train = DataLoader.xy_split_dataset(train_data)\n",
    "X_test, y_test = DataLoader.xy_split_dataset(test_data)\n",
    "\n",
    "# Show structure of new dataset\n",
    "print(f'{train_data[0]}\\n{train_data[-1]}\\nTranslation: {translate}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuber of classifiers: 9\n",
      "Accuracy: 96.52% | Precision: 93.02% | Recall: 97.56% | F1 Score: 95.24%\n"
     ]
    }
   ],
   "source": [
    "# Test the AdaBoost Model\n",
    "model = ModelTesting(X_train, y_train, X_test, y_test)\n",
    "n_cls = model.optim(Max_Cls=20, Stop=True, Gap=1)\n",
    "acc = model.accuracy()\n",
    "pre = model.precision()\n",
    "rec = model.recall()\n",
    "f1s = model.f1score()\n",
    "\n",
    "# Print the Results\n",
    "print(f'Nuber of classifiers: {n_cls}\\n'\n",
    "      f'Accuracy: {round(acc*100, 2)}% | Precision: {round(pre*100, 2)}% | '\n",
    "      f'Recall: {round(rec*100, 2)}% | F1 Score: {round(f1s*100, 2)}%')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01. Decision: radius_worst | Threshold: Greater Than 106.05 is M (Positive) | Power of Rule: 1.241\n",
      "02. Decision: compactness_worst | Threshold: Greater Than 0.142 is M (Positive) | Power of Rule: 0.92\n",
      "03. Decision: diagnosis | Threshold: Greater Than 20.235 is M (Positive) | Power of Rule: 0.647\n",
      "04. Decision: perimeter_mean | Threshold: Greater Than 0.09 is M (Positive) | Power of Rule: 0.473\n",
      "05. Decision: fractal_dimension_se | Threshold: Greater Than 23.35 is M (Positive) | Power of Rule: 0.501\n",
      "06. Decision: texture_se | Threshold: Greater Than 35.185 is M (Positive) | Power of Rule: 0.572\n",
      "07. Decision: smoothness_worst | Threshold: Greater Than 0.208 is M (Positive) | Power of Rule: 0.503\n",
      "08. Decision: area_se | Threshold: Less Than 0.012 is M (Positive) | Power of Rule: 0.52\n",
      "09. Decision: perimeter_worst | Threshold: Greater Than 0.137 is M (Positive) | Power of Rule: 0.517\n"
     ]
    }
   ],
   "source": [
    "# Show the decision-making process\n",
    "model.Model.show_classification(cancer_raw, translate)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
