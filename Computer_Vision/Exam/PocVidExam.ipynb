{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### PocVid Final Exam"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74ea6901a3613ccd"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-22T09:31:13.801460600Z",
     "start_time": "2024-01-22T09:31:12.214509200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import cv2\n",
    "import time, numpy as np\n",
    "from skimage import color\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "# from skimage import draw\n",
    "from IPython import display\n",
    "from skimage import morphology\n",
    "# from IPython.display import Video\n",
    "from skimage.color import rgb2gray\n",
    "import skimage\n",
    "from skimage.measure import label\n",
    "# from skimage.measure import regionprops\n",
    "\n",
    "plt.rc('font', **{'family' : 'DejaVu Sans', 'weight' : 'normal'})\n",
    "plt.rcParams['font.size'] = 18"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Add text overlay into video frame\n",
    "\n",
    "def add_text_to_frame(frame, text, position=(30, 30), font=cv2.FONT_HERSHEY_SIMPLEX, font_scale=0.3, color=(0, 255, 0), thickness=1):\n",
    "    frame_with_text = frame.copy()\n",
    "    cv2.putText(frame_with_text, text, position, font, font_scale, color, thickness)\n",
    "    return frame_with_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T09:31:13.811203300Z",
     "start_time": "2024-01-22T09:31:13.805214800Z"
    }
   },
   "id": "12a60e992b1299ce",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('hra.mov')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T09:31:13.833994200Z",
     "start_time": "2024-01-22T09:31:13.811203300Z"
    }
   },
   "id": "b2b28668aa2810dc",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame width: 1142\n",
      "Frame height: 1260\n",
      "Length (frames count): 4942\n",
      "Frames per second: 59.66197183098591\n"
     ]
    }
   ],
   "source": [
    "# Get the frame width of the video\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "\n",
    "# Get the frame height of the video\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Get the total number of frames in the video\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Get the frames per second (fps) of the video\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Print the obtained video properties\n",
    "print(\"Frame width:\", frame_width)\n",
    "print(\"Frame height:\", frame_height)\n",
    "print(\"Length (frames count):\", length)\n",
    "print(\"Frames per second:\", fps)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T09:31:13.848042400Z",
     "start_time": "2024-01-22T09:31:13.838810500Z"
    }
   },
   "id": "46ec6e537d4182b3",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_num_of_points(img):\n",
    "    _, image = cap.read(img)\n",
    "    image_lab = color.rgb2lab(image)\n",
    "    points = ((image_lab[:, :, 1] > 8 - 5) * (image_lab[:, :, 1] < 8 + 5)\n",
    "              * (image_lab[:, :, 2] > -16 - 5) * (image_lab[:, :, 2] < -16 + 5))\n",
    "\n",
    "    diff_thresholded_processed =  morphology.dilation(morphology.erosion(morphology.closing(morphology.closing(morphology.closing(morphology.remove_small_holes(points, area_threshold=1000), morphology.square(5)))), morphology.square(5)), morphology.square(5))\n",
    "\n",
    "    label_img = label(diff_thresholded_processed, connectivity=2)\n",
    "\n",
    "    return len(np.unique(label_img))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T09:31:13.857158500Z",
     "start_time": "2024-01-22T09:31:13.846953800Z"
    }
   },
   "id": "466bb008511fcf34",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('hra.mov')\n",
    "MAX_POINTS = get_num_of_points(cap.read()[1])\n",
    "\n",
    "cv2.namedWindow('Pac-Man', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Pac-Man', 800, 800)  # Adjust the dimensions as needed\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    points = get_num_of_points(frame)\n",
    "\n",
    "    frame = add_text_to_frame(frame, f'Score: {points}', position=(10,10), color=(0,0,255))\n",
    "\n",
    "    # Display the frame with bounding boxes\n",
    "    cv2.imshow('Pac-Man', frame)\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "    time.sleep(.05)\n",
    "\n",
    "# Release the video capture and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T09:37:02.672775400Z",
     "start_time": "2024-01-22T09:36:57.292602100Z"
    }
   },
   "id": "d523af790f004092",
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
