{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nc9lDMhIPxtC"
   },
   "source": [
    "# Cvičenie 5: Metodológia trénovania a vyhodnotenia neurónových sietí"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvLLyngUPxtC"
   },
   "source": [
    "Cieľom tohto cvičenia je oboznámiť vás so základnými krokmi, ktoré by ste mali vykonať pri trénovaní neurónových sietí. Tieto kroky platia všeobecne pre všetky metódy umelej inteligencie, ale niektoré úlohy sú špecifické pre neurónové siete. Metodológiu vysvetlíme na klasifikačnej úlohe, na definíciu a trénovanie neurónovej siete budeme používať knižnicu [PyTorch](https://pytorch.org/\\). Ak PyTorch ešte nemáte nainštalovaný, nainštalujte si ho podľa [tohto návodu](https://github.com/DominikVranay/neural-networks-course/blob/master/labs/lab00-getting-started.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EcyOCj-UPxtD"
   },
   "source": [
    "Postup vývoja neurónových sietí vieme rozdeliť do nasledujúcich krokov:\n",
    "1. predspracovanie údajov\n",
    "2. návrh siete\n",
    "3. trénovanie siete\n",
    "4. vyhodnotenie siete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCvODXP3PxtD"
   },
   "source": [
    "## 1. Predspracovanie údajov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djfA4DB2PxtD"
   },
   "source": [
    "Predspracovanie údajov je prvý krok, ktorý v sebe zahŕňa hneď niekoľko úloh:\n",
    "* načítanie datasetu\n",
    "* výber príznakov\n",
    "* normalizácia hodnôt\n",
    "* vektorizácia vstupov a výstupov\n",
    "* rozdelenie datasetu na trénovaciu, testovaciu a validačnú množinu.\n",
    "\n",
    "Postup pri predspracovaní údajov ukážeme na Iris datasete. Stiahnite si [dataset s implementáciou neurónovej siete](sources/lab05/lab5.zip)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIohQ-tyPxtD"
   },
   "source": [
    "### 1.1. Načítanie datasetu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a572Hvb4PxtD"
   },
   "source": [
    "Na načítanie datasetu existujú rôzne knižnice pre Python, jedna populárna z nich je knižnica `pandas`. Knižnica dokáže načítať rôzne formátované dáta, napríklad formáty csv, html, json, hdf5 a SQL. Náš dataset vieme načítať priamo zo súboru csv nasledovným spôsobom:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TIKb3Va4PxtE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5f47763a-6d34-4ebe-ca5a-141318340db5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthcm         Species\n",
      "0              5.1           3.5            1.4           0.2     Iris-setosa\n",
      "1              4.9           3.0            1.4           0.2     Iris-setosa\n",
      "2              4.7           3.2            1.3           0.2     Iris-setosa\n",
      "3              4.6           3.1            1.5           0.2     Iris-setosa\n",
      "4              5.0           3.6            1.4           0.2     Iris-setosa\n",
      "..             ...           ...            ...           ...             ...\n",
      "145            6.7           3.0            5.2           2.3  Iris-virginica\n",
      "146            6.3           2.5            5.0           1.9  Iris-virginica\n",
      "147            6.5           3.0            5.2           2.0  Iris-virginica\n",
      "148            6.2           3.4            5.4           2.3  Iris-virginica\n",
      "149            5.9           3.0            5.1           1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv('iris.csv')\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00obcd0kPxtE"
   },
   "source": [
    "Načítaný dataset má typ DataFrame. K ľubovoľným stĺpcom sa dostaneme zadaním názvu stĺpca ako index datasetu. Ak chceme zobraziť viac stĺpcov, index musí byť zoznam s názvami týchto stĺpcov."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "izK7C_GlPxtE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "3308634b-b1ce-4f8d-fcd0-32d54eeff34f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      5.1\n",
      "1      4.9\n",
      "2      4.7\n",
      "3      4.6\n",
      "4      5.0\n",
      "      ... \n",
      "145    6.7\n",
      "146    6.3\n",
      "147    6.5\n",
      "148    6.2\n",
      "149    5.9\n",
      "Name: SepalLengthCm, Length: 150, dtype: float64\n",
      "     SepalLengthCm  SepalWidthCm\n",
      "0              5.1           3.5\n",
      "1              4.9           3.0\n",
      "2              4.7           3.2\n",
      "3              4.6           3.1\n",
      "4              5.0           3.6\n",
      "..             ...           ...\n",
      "145            6.7           3.0\n",
      "146            6.3           2.5\n",
      "147            6.5           3.0\n",
      "148            6.2           3.4\n",
      "149            5.9           3.0\n",
      "\n",
      "[150 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# select only column SepalLengthCm\n",
    "print(dataset['SepalLengthCm'])\n",
    "\n",
    "# select columns SepalLengthCm and SepalWidthCm\n",
    "print(dataset[['SepalLengthCm', 'SepalWidthCm']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GusTOsIJPxtE"
   },
   "source": [
    "Alternatívne vieme zobraziť stĺpce ako keby boli parametrom objektu dataset, alebo vieme použiť aj poradové číslo stĺpca (znak `:` pred čiarkou vyjadruje všetky riadky)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "AywnxfncPxtF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      5.1\n",
      "1      4.9\n",
      "2      4.7\n",
      "3      4.6\n",
      "4      5.0\n",
      "      ... \n",
      "145    6.7\n",
      "146    6.3\n",
      "147    6.5\n",
      "148    6.2\n",
      "149    5.9\n",
      "Name: SepalLengthCm, Length: 150, dtype: float64\n",
      "0      5.1\n",
      "1      4.9\n",
      "2      4.7\n",
      "3      4.6\n",
      "4      5.0\n",
      "      ... \n",
      "145    6.7\n",
      "146    6.3\n",
      "147    6.5\n",
      "148    6.2\n",
      "149    5.9\n",
      "Name: SepalLengthCm, Length: 150, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(dataset.SepalLengthCm)\n",
    "print(dataset.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1vKrwJ5-PxtF"
   },
   "source": [
    "K riadkom pristupujeme cez číselné indexy, pričom dokopy ich môžeme mať až tri. Prvé číslo vyjadruje poradové číslo prvého riadku, druhé číslo poradové číslo posledného riadku (vľavo uzavretý interval, podľa [pravidiel indexovania v Pythone](https://www.digitalocean.com/community/tutorials/how-to-index-and-slice-strings-in-python-3)), a tretie číslo step. Takto vieme napríklad vypísať každý druhý riadok z intervalu 1-10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mMpiS_IRPxtF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthcm      Species\n",
      "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "4            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "6            4.6           3.4            1.4           0.3  Iris-setosa\n",
      "8            4.4           2.9            1.4           0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0:10:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rcDjsRLMPxtF"
   },
   "source": [
    "Alternatívne môžete použiť aj `loc` funkciu DataFrame-ov (podľa indexu atribútu; druhý index vyjadruje otvorený interval), alebo `iloc` funkciu (podľa poradia; druhý index vyjadruje otvorený interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uavLPBTWPxtF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthcm      Species\n",
      "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "4            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "6            4.6           3.4            1.4           0.3  Iris-setosa\n",
      "8            4.4           2.9            1.4           0.2  Iris-setosa\n",
      "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthcm      Species\n",
      "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "4            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "6            4.6           3.4            1.4           0.3  Iris-setosa\n",
      "8            4.4           2.9            1.4           0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "print(dataset.loc[0:9:2])\n",
    "print(dataset.iloc[0:9:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dtosNAvhPxtF"
   },
   "source": [
    "Indexovanie riadkov a stĺpcov viete aj kombinovať, na poradí nezáleží:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wewoolAfPxtF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5.1\n",
      "2    4.7\n",
      "4    5.0\n",
      "6    4.6\n",
      "8    4.4\n",
      "Name: SepalLengthCm, dtype: float64\n",
      "0    5.1\n",
      "2    4.7\n",
      "4    5.0\n",
      "6    4.6\n",
      "8    4.4\n",
      "Name: SepalLengthCm, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(dataset[:10:2]['SepalLengthCm'])\n",
    "print(dataset['SepalLengthCm'][:10:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4QVZBn9PxtG"
   },
   "source": [
    "Z datasetu viete vybrať iba niektoré riadky aj na základe hodnoty niektorého atribútu použitím `lambda` funkcie. Napríklad, pre všetky riadky, kde hodnota SepalLengthCm je viac ako 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "gW8kvngdPxtG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthcm         Species\n",
      "0              5.1           3.5            1.4           0.2     Iris-setosa\n",
      "5              5.4           3.9            1.7           0.4     Iris-setosa\n",
      "10             5.4           3.7            1.5           0.2     Iris-setosa\n",
      "14             5.8           4.0            1.2           0.2     Iris-setosa\n",
      "15             5.7           4.4            1.5           0.4     Iris-setosa\n",
      "..             ...           ...            ...           ...             ...\n",
      "145            6.7           3.0            5.2           2.3  Iris-virginica\n",
      "146            6.3           2.5            5.0           1.9  Iris-virginica\n",
      "147            6.5           3.0            5.2           2.0  Iris-virginica\n",
      "148            6.2           3.4            5.4           2.3  Iris-virginica\n",
      "149            5.9           3.0            5.1           1.8  Iris-virginica\n",
      "\n",
      "[118 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.loc[lambda df:df.SepalLengthCm > 5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUDwGtDRPxtG"
   },
   "source": [
    "Všetky tieto podmnožiny majú typ `DataFrame`. Ak chcete hodnoty použiť ako zoznam, resp. zoznam zoznamov, musíte pridať `values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "x5_05km0PxtG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([5.1, 4.9, 4.7, 4.6, 5. , 5.4, 4.6, 5. , 4.4, 4.9])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['SepalLengthCm'][:10:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hbfqyQMPxtG"
   },
   "source": [
    "### 1.2. Výber príznakov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsZJwMqePxtG"
   },
   "source": [
    "Pred výberom príznakov potrebujeme získať intuitívne pochopenie datasetu a vzťahov medzi jednotlivými atribútmi a výsledkom klasifikácie. V tomto nám pomôže knižnica `Seaborn`, ktorá slúži na vizualizáciu údajov a využíva knižnicu `matplotlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pVdqMfjiPxtG",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set plot style\n",
    "sns.set(style=\"ticks\")\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# create plots over all dataset; for subset use iloc indexing\n",
    "sns.pairplot(dataset, hue=\"Species\")\n",
    "\n",
    "# display plots using matplotlib\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zc4_7OGmPxtG"
   },
   "source": [
    "Uvedený kód namapuje záznamy z datasetu v každom možnom príznakovom priestore vo dvojiciach príznakov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ec3C0hGgPxtG"
   },
   "source": [
    "![Vizualizácia datasetu](https://github.com/DominikVranay/neural-networks-course/blob/master/labs/sources/lab05/5.1-dataset-visualization.png?raw=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URrhteBSPxtH"
   },
   "source": [
    "Z grafov vidíme, že ani jedna kombinácia nám nedá lineárne separovateľný dataset, budeme teda používať všetky príznaky, ktoré vyberieme pomocou knižnice `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "TSXkkoIhPxtH"
   },
   "outputs": [],
   "source": [
    "# split data into input (X - select the first four columns) and output (y - select last column)\n",
    "X = dataset.iloc[:, :4].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S9AQ3kxVPxtH"
   },
   "source": [
    "### 1.3. Normalizácia hodnôt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4rD6WnpJPxtH"
   },
   "source": [
    "Normalizácia hodnôt sa používa najmä pre zložitejšie datasety a urýchli proces trénovania neurónových sietí, ktoré lepšie pracujú s dátami z istého intervalu. Počas normalizácie sa číselné hodnoty namapujú zvyčajne na interval 0 až 1.\n",
    "\n",
    "Neskôr boli vyvinuté špeciálne vrstvy neurónovej siete práve pre normalizáciu, dnes sa skôr používa takto automatizovaný spôsob normalizácie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uDhV-bZPxtH"
   },
   "source": [
    "### 1.4. Vektorizácia vstupov a výstupov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAKSb_AKPxtH"
   },
   "source": [
    "Kým neurónové siete dokážu spracovať iba číselné hodnoty, skoro všetky datasety obsahujú aj nečíselné údaje (reťazce, kategórie, booleovské hodnoty, atď.). Preto je potrebné, aby sme tieto hodnoty premenili na vektorovú reprezentáciu. Pri vektorizácii upravíme výstupy na formu *n* čísel, kde *n* je počet tried pri klasifikácii. Každý vektor bude obsahovať práve jednu 1 a ostatné hodnoty budú 0, tieto čísla vyjadrujú mieru príslušnosti k jednotlivým triedam.\n",
    "\n",
    "V našom datasete potrebujeme upraviť očakávaný výstup, ktorý zatiaľ má formu reťazca. Pri vektorizácii vieme využiť `LabelEncoder` z knižnice `scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rjY5tckYPxtH",
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "# transform string labels into number values 0, 1, 2\n",
    "y1 = encoder.fit_transform(y)\n",
    "print(y1)\n",
    "\n",
    "# transform number values into vector representation\n",
    "Y = pd.get_dummies(y1).values\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lT3n8LEjPxtI"
   },
   "source": [
    "**Poznámka:** v niektorých prípadoch dokážete reťazce nahradiť jednoduchými číslami, takýto spôsob ale predpokladá, že čísla, ktoré sú blízko sebe vyjadrujú koncepty, ktoré sú veľmi podobné. Napríklad, ak máme stĺpec s hodnotami *low*, *middle*, *high*, tieto hodnoty vieme nahradiť číslami 1, 2 a 3. Rovnaký spôsob ale nemôžeme použiť s hodnotami ako napríklad značky auta: *Škoda* (1), *Audi* (2), *Lada* (3), pretože neurónová sieť by predpokladala, že Lada (3) je viac podobná Audi (2) ako Škodovke (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJ5yd8dLPxtI"
   },
   "source": [
    "### 1.5. Rozdelenie datasetu na trénovaciu, testovaciu a validačnú množinu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U-IsJcHHPxtI"
   },
   "source": [
    "Ďalšou úlohou je rozdelenie množiny na trénovaciu a testovaciu. Na to použijeme ďalšiu funkciu z knižnice `scikit-learn`, a to `train_test_split` ([dokumentácia](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)), ktorá zachová poradie vstupov a výstupov a má tri dôležité parametre:\n",
    "1. zoznam vstupov\n",
    "2. zoznam výstupov\n",
    "3. test_size - veľkosť testovacej množiny medzi 0 a 1 (môžete použiť aj train_size)\n",
    "\n",
    "Pre opakovateľnosť trénovania je odporúčané používať random seed zadaním parametra `random_state`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "l-aJfAihPxtI"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)\n",
    "X_train = torch.Tensor(X_train)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_train = torch.Tensor(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MtdUZSzTPxtI"
   },
   "source": [
    "Validačná množina sa pri jednoduchých datasetoch až tak často nepoužíva, slúži ako testovacia množina počas fázy trénovania a môže byť použitá ako podmienka pre ukončenie trénovania."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BLBbh4sqPxtI"
   },
   "source": [
    "## 2. Návrh siete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yE7BdENCPxtI"
   },
   "source": [
    "Na definíciu siete použijeme knižnicu PyTorch, v ktorej potrebujem tri veci na vytvorenie jednoduchej siete:\n",
    "\n",
    "1. model - v tomto kroku použijeme jednoduchý feed-forward sekvenčný model ([dokumentácia](https://keras.io/models/sequential/))\n",
    "2. vrstvy - použijeme iba plne prepojené dense vrstvy ([dokumentácia](https://keras.io/layers/core/#dense))\n",
    "3. optimalizátor - algoritmus, ktorý nám zadefinuje spôsob trénovania siete; my použijeme optimalizátor Adam ([dokumentácia](https://keras.io/optimizers/#adam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cHnH9edWPxtI"
   },
   "source": [
    "V PyTorchi môžeme vytvoriť priamo sekvenčný model s vrstvami. Pri definícii vrstiev potrebujeme zadať počet vstupných a výstupných neurónov vo vrstve a aktivačná funkcia je vlastná vrstva. Počet neurónov v poslednej vrstve má zodpovedať formátu výstupu siete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4rSFWkOgPxtJ"
   },
   "outputs": [],
   "source": [
    "model = torch.nn.Sequential(\n",
    "  # TODO: add dense layer with 4, 10 neurons and tanh activation function\n",
    "  torch.nn.Linear(4,10),\n",
    "  torch.nn.Tanh(),\n",
    "  # TODO: add dense layer with 10, 8 neurons and tanh activation function\n",
    "  torch.nn.Linear(10,8),\n",
    "  torch.nn.Tanh(),\n",
    "  # TODO: add dense layer with 8, 6 neurons and tanh activation function\n",
    "  torch.nn.Linear(8,6),\n",
    "  torch.nn.Tanh(),\n",
    "  # TODO: add dense layer with 6, 3 neurons and softmax activation function\n",
    "  torch.nn.Linear(6,3),\n",
    "  #torch.Softmax(-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZPgrjDvPxtJ"
   },
   "source": [
    "Pred trénovaním siete ešte potrebujeme zadefinovať spôsob trénovania cez nasledujúce parametre:\n",
    "* optimizer (optimalizátor)\n",
    "* loss function/criterion (chybová funkcia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Wy9KXEaXPxtJ"
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "#criterion = torch.nn.MSELoss()\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRVzXj6PPxtJ"
   },
   "source": [
    "## 3. Trénovanie siete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UB-QUqJ7PxtJ"
   },
   "source": [
    "Ak sme spokojní so sieťou, môžeme ju začať trénovať pomocou vlastného trénovacieho loopu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "IWrvg0Q1PxtJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.13427734375 accuracy: 0.30833333333333335\n",
      "Loss: 1.0766555070877075 accuracy: 0.36666666666666664\n",
      "Loss: 0.9180667400360107 accuracy: 0.7\n",
      "Loss: 0.6473805904388428 accuracy: 0.7416666666666667\n",
      "Loss: 0.5135729908943176 accuracy: 0.8666666666666667\n",
      "Loss: 0.41171783208847046 accuracy: 0.9333333333333333\n",
      "Loss: 0.3230969309806824 accuracy: 0.9583333333333334\n",
      "Loss: 0.24729567766189575 accuracy: 0.975\n",
      "Loss: 0.19200201332569122 accuracy: 0.975\n",
      "Loss: 0.15532924234867096 accuracy: 0.9833333333333333\n",
      "Loss: 0.13116350769996643 accuracy: 0.9833333333333333\n",
      "Loss: 0.11474630236625671 accuracy: 0.9833333333333333\n",
      "Loss: 0.1031409278512001 accuracy: 0.9833333333333333\n",
      "Loss: 0.09457892924547195 accuracy: 0.9833333333333333\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(700):\n",
    "    preds = model(X_train)\n",
    "    loss = criterion(preds, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    if epoch%50 == 0:\n",
    "        print(\"Loss:\", loss.detach().item(), \"accuracy:\", (y_train.argmax(-1) == preds.argmax(-1)).sum().item()/len(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qe6aBi7bPxtJ"
   },
   "source": [
    "## 4. Vyhodnotenie siete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IdW8jCvaPxtJ"
   },
   "source": [
    "Vyhodnotenie siete pozostáva z dvoch základných úloh: testovanie a vyhodnotenie. Pre testovanie musíme získať predikcie modelu podobne ako pri trénovaní."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "46xJ5dnMPxtK"
   },
   "outputs": [],
   "source": [
    "y_pred = model(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JTxN-fJzPxtK"
   },
   "source": [
    "Ďalej porovnáme ozajstné výstupy s očakávanými. Keďže výstup má vektorovú reprezentáciu, potrebujeme zistiť pozíciu kde sa nachádza najväčšia hodnota vo vektore. V tomto nám pomôže knižnica `numpy`, ktorú sme zatiaľ nepoužili explicitne, ale podporuje všetky už použité knižnice. Jedná sa o efektívne a optimalizované riešenie práce s poľami.\n",
    "\n",
    "Pre vyhodnotenie našej siete použijeme konfúznu maticu. Konfúzna matica je tabuľková reprezentácia, kde v riadkoch máme očakávané triedy a v stĺpcoch vypočítané (predikované). V bunkách tabuľky sú uložené počty príkladov klasifikované v danej kombinácii očakávanej a predikovanej triedy. Ideálny klasifikátor bude mať všetky hodnoty po hlavnej diagonále (ďalšie informácie nájdete na [wikipédii](https://en.wikipedia.org/wiki/Confusion_matrix))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "efHXMGrUPxtK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0 13  0]\n",
      " [ 0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y_test_class = np.argmax(y_test,axis=1)\n",
    "y_pred_class = np.argmax(y_pred.detach().numpy(),axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(confusion_matrix(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mnq_uYR7PxtK"
   },
   "source": [
    "Z konfúznej matici potom vieme vypočítať ďalšie metriky, ako presnosť (accuracy), návratnosť (recall) a precizita (precision):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4eUZ-I9FPxtK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        13\n",
      "           2       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        30\n",
      "   macro avg       1.00      1.00      1.00        30\n",
      "weighted avg       1.00      1.00      1.00        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_class, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eszDMvD6PxtK"
   },
   "source": [
    "Presnosť popisuje samotný klasifikátor a vypočíta sa nasledovne:\n",
    "\n",
    "$ACC = \\frac{TP + TN}{P + N}$\n",
    "\n",
    "kde TP + TN je suma správne klasifikovaných príkladov (na hlavnej diagonále) a P + N je počet všetkých príkladov."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0aJaeOXePxtK"
   },
   "source": [
    "Návratnosť a precizita popisujú klasifikátor pre danú triedu, vypočítajú sa nasledovne:\n",
    "\n",
    "$REC = \\frac{TP}{TP + FN}$\n",
    "\n",
    "$PREC = \\frac{TP}{TP + FP}$\n",
    "\n",
    "kde TP je počet správne klasifikovaných príkladov z danej triedy, P je počet príkadov z danej triedy v testovacej množine a FP je počet príkladov z testovacej množiny nesprávne klasifikovaných do tejto triedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbReAC-RPxtK"
   },
   "source": [
    "Metóda `classification_report` vypočíta ešte hodnotu F1, ktorá je harmonický priemer návratnosti a precizity:\n",
    "\n",
    "$F1 = 2 \\cdot \\frac{REC \\cdot PREC}{REC + PREC}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
