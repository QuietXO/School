{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4c6Osd5S-Ws"
      },
      "source": [
        "# Cvičenie 2: Perceptrón\n",
        "\n",
        "Na dnešnom cvičení naimplementujeme najjednoduchšiu neurónovú sieť, teda perceptrón. Na úvod si zopakujeme, čo je to perceptrón, z akých častí sa skladá, aké má parametre a ako funguje - ako sa vypočítava vstup a ako sa perceptrón učí z dát. Pri tom nám pomôže štruktúra perceptrónu:\n",
        "\n",
        "![Štruktúra perceptrónu](https://github.com/DominikVranay/neural-networks-course/blob/master/labs/sources/lab02/2.1-perceptron-structure.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3YsQvGgS-Wv"
      },
      "source": [
        "## 1. Prvý pohľad na kód\n",
        "\n",
        "Stiahnite si [kostru riešenia](sources/lab02/lab2.zip), ktorá obsahuje čiastočnú implementáciu perceptrónu a dataset, ktorý použijeme na trénovanie. Je ním dataset [Iris](https://archive.ics.uci.edu/ml/datasets/iris), ktorý sa používa veľmi často pri ukážkach metód strojového učenia.\n",
        "\n",
        "Kód (`lab2-perceptron.py`) obsahuje definíciu triedy `Perceptron` aj s deklaráciami členských metód. Skript navyše obsahuje funkcie `plot_decision_regions` (vizualizuje rozhodovanie perceptrónu) a `plot_dataset` (vizualizuje dataset).\n",
        "\n",
        "Po spustení skriptu by sa vám mal zobraziť graf s datasetom. Z grafu zistite, či je možné natrénovať perceptrón na klasifikáciu dát z datasetu Iris."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
        "    markers = ('s', 'x', 'o', '^', 'v')\n",
        "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
        "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
        "\n",
        "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
        "                           np.arange(x2_min, x2_max, resolution))\n",
        "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
        "    Z = Z.reshape(xx1.shape)\n",
        "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
        "    plt.xlim(xx1.min(), xx1.max())\n",
        "    plt.ylim(xx2.min(), xx2.max())\n",
        "\n",
        "    for idx, cl in enumerate(np.unique(y)):\n",
        "        plt.scatter(x=X[y == cl, 0], y=X[y == cl, 1],\n",
        "                    alpha=0.8, c=cmap(idx),\n",
        "                    marker=markers[idx], label=cl)\n",
        "\n",
        "    plt.xlabel('sepal length [cm]')\n",
        "    plt.ylabel('petal length [cm]')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def plot_dataset(X):\n",
        "    plt.scatter(X[:50, 0], X[:50, 1], color='red', marker='o', label='setosa')\n",
        "    plt.scatter(X[50:100, 0], X[50:100, 1], color='blue', marker='x', label='versicolor')\n",
        "    plt.xlabel('petal length')\n",
        "    plt.ylabel('sepal length')\n",
        "    plt.legend(loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "dFrame = pd.read_csv(\"iris.data\", header=None)\n",
        "y = dFrame.iloc[0:100, 4].values\n",
        "y = np.where(y == 'Iris-setosa', -1, 1)\n",
        "X = dFrame.iloc[0:100, [0, 2]].values\n",
        "plot_dataset(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "-UBsTJk1ANDo",
        "outputId": "e73b2470-2231-4fd5-bd3a-ac8637e49141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-80cf94e8afa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mdFrame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iris.data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Iris-setosa'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'iris.data'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hE67S7OS-Wy"
      },
      "source": [
        "## 2. Implementácia doprednej časti perceptrónu\n",
        "\n",
        "V ďalšej časti postupne implementujeme doprednú časť, teda predikciu, perceptrónu. K tomu potrebujete implementovať tri funkcie: konštruktor, `get_sum` a `predict`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron:\n",
        "    def __init__(self, input_no, learning_rate):\n",
        "        # TODO: initialize all parameters\n",
        "        self.weights = np.random.rand(input_no) * 2 - 1\n",
        "        self.bias = 0\n",
        "        self.lr = learning_rate\n",
        "\n",
        "    def get_sum(self, input_vector):\n",
        "        # TODO: calculate forward pass sum\n",
        "        return no.dot(input_vector, self.weights) + self.bias\n",
        "\n",
        "    def predict(self, input_vector):\n",
        "        # TODO: return result of activation 1 for class 1, -1 for class 2\n",
        "        return np.where(self.get_sum(input_vector) >= 0.0, 1, -1)\n",
        "\n",
        "    def fit(self, X, y, epochs=10):\n",
        "        # TODO: train perceptron\n",
        "        for epoch in range(epochs):\n",
        "            incorrect = 0\n",
        "            for x, y_hat in zip(X, y):\n",
        "              y_pred = self.predict(x)\n",
        "              diff = y_hat - y_pred\n",
        "              if diff:\n",
        "                  incorrect +=1\n",
        "              update = self.lr * diff\n",
        "              self.weights += x * update\n",
        "              self.bias += update\n",
        "        print(incorrect)"
      ],
      "metadata": {
        "id": "7sorJuSxAuxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnzRzz2uS-Wy"
      },
      "source": [
        "### 2.1. Konštruktor\n",
        "\n",
        "Konštruktor triedy má dva parametre:\n",
        "* `input_no` - celé číslo reprezentujúce počet vstupov do perceptrónu\n",
        "* `learning_rate` - učiaci parameter perceptrónu, vyjadruje mieru učenia z nových dát.\n",
        "\n",
        "Na základe parametrov konštruktora inicializujte potrebné členské premenné perceptrónu."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLVgdUkFS-Wy"
      },
      "source": [
        "### 2.2. `get_sum`\n",
        "\n",
        "Funkcia `get_sum` slúži na výpočet váženej sumy vstupov na základe príslušných váh. Pre jednoduchosť riešenia rovno pripočítame aj prah (bias) perceptrónu. Pre výpočet sumy môžete použiť metódu z knižnice `numpy`. Vstupom do funkcie je vektor vstupov (`input_vector`), ktorý môže reprezentovať jeden vstupný príklad alebo niekoľko vstupných príkladov (ak pracujete v knižnici `numpy`, nie je potrebné zvlásť ošetriť jednotlivé prípady použitia)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vd822RX6S-Wz"
      },
      "source": [
        "### 2.3. `predict`\n",
        "\n",
        "Funkcia `predict` vypočíta celkový výstup perceptrónu pre daný vstup (parameter `input_vector`). Funkcia má vrátiť 1 pre vstup, kde vážená suma aj s biasom je minimálne 0 a -1 pre záporné sumy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPBP6FoRS-Wz"
      },
      "source": [
        "### 2.4. Testovanie\n",
        "\n",
        "Aby ste otestovali riešenie, skúste predikovať výstup pre každý riadok z datasetu a vypíšte výsledok do konzoly - pre jednoduchosť testovania odporúčame, aby ste všetky parametre perceptrónu inicializovali na 0."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uz9BtRMBA-kv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAVBgxaFS-Wz"
      },
      "source": [
        "## 3. Trénovanie perceptrónu\n",
        "\n",
        "Posledná chýbajúca metóda triedy `Perceptron` je `fit`, ktorá slúži na trénovanie perceptrónu. V tomto kroku ju naimplementujete pričom použite nasledujúci spôsob aktualizácie váh:\n",
        "\n",
        "$w_{i}(t+1)=w_{i}(t) + x_{i} \\cdot \\gamma \\cdot (\\hat{y} - y)$\n",
        "\n",
        "kde:\n",
        "* $w_{i}(t+1)$ je hodnota váhy $w_{i}$ v čase t+1,\n",
        "* $x_{i}$ je hodnota i-tej vstupnej hodnoty\n",
        "* $\\gamma$ je učiaci parameter\n",
        "* $\\hat{y}$ je očakávaný výstup\n",
        "* $y$ je vypočítaný výstup."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2oglbriS-Wz"
      },
      "source": [
        "Funkcia `fit` má tri parametre:\n",
        "* `X` - vstupné príklady (jeden vstup alebo pole vstupov)\n",
        "* `y` - príslušné výstupné príklady (jeden výstup alebo pole výstupov)\n",
        "* `epochs` - počet trénovacích epoch, defaultne 10.\n",
        "\n",
        "Pre pozorovanie vývoja trénovania perceptrónu môžete vypísať počet chybných výstupov pre celý dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jtwnzUHbBKIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylUio8yZS-W0"
      },
      "source": [
        "## 4. Testovanie perceptrónu\n",
        "\n",
        "Ak ste úspešne implementovali všetky funkcie, môžete natrénovať perceptrón pomocou dát z datasetu Iris. Dataset je už predspracovaný vo funkcii `main`. Vašou úlohou je vytvoriť nový perceptrón a natrénovať ho na dátach. Pre vizualizáciu úspešnosti trénovania vykreslite rozhodovanie perceptrónu pred a po trénovaní pomocou funkcie `plot_decision_regions`.\n",
        "\n",
        "Ukážkové riešenie cvičenia nájdete na [tejto adrese](sources/lab02/perceptron-solution.py). Aplikáciu pre XOR problém nájdete na [tejto adrese](sources/lab02/perceptron-xor.py)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Perceptron(4, 0.1)\n",
        "model.fit(X, y)\n",
        "#plot_decision_region()"
      ],
      "metadata": {
        "id": "SF8zJgeyBLMY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}